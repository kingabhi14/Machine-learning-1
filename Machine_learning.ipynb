{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#THEORETICAL QUESTIONS:"
      ],
      "metadata": {
        "id": "REmFXuMuaiND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "\n",
        ".Logistic regression and linear regression are both used to model relationships between variables, but they differ in the type of dependent variable they handle.\n",
        "\n",
        " Linear regression predicts a continuous outcome, while logistic regression predicts a categorical outcome, specifically the probability of belonging to a particular class"
      ],
      "metadata": {
        "id": "5AkbyhT8bBsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What is the mathematical equation of Logistic Regression?\n",
        "\n",
        ".The core equation of logistic regression models the probability of an event occurring, typically represented as '1', given a set of input features (X) and a set of coefficients (β). It uses the sigmoid function (also known as the logistic function) to transform the linear combination of input features into a probability between 0 and 1.\n",
        "\n",
        "The equation is generally expressed as:\n",
        "\n",
        "P(Y=1 | X) = 1 / (1 + e^(-(β₀ + β₁X₁ + β₂X₂ + ... + βₚXₚ)))"
      ],
      "metadata": {
        "id": "5MriEId2bt8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Why do we use the Sigmoid function in Logistic Regression?\n",
        "\n",
        ".The sigmoid function is used in Logistic Regression to transform the output of the linear model (which can be any real number) into a probability between 0 and 1. This is crucial for binary classification tasks because the output of a logistic regression model is interpreted as the probability of an event occurring, not just a simple classification.\n"
      ],
      "metadata": {
        "id": "HXYj91XCcUNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is the cost function of Logistic Regression?\n",
        "\n",
        ".In machine learning, the function to be optimized is called the loss function or cost function. We use the loss function to determine how well our model fits the data. A suitable loss function in logistic regression is called the Log-Loss, or binary cross-entropy.\n"
      ],
      "metadata": {
        "id": "V_uNFFsacrfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is Regularization in Logistic Regression? Why is it needed?\n",
        "\n",
        ".Regularization in logistic regression is a technique used to prevent overfitting by adding a penalty term to the cost function. This penalty term discourages the model from assigning overly large coefficients to features, thereby simplifying the model and improving its ability to generalize to unseen data.\n",
        "\n",
        " Regularization Needed:\n",
        "\n",
        "Overfitting:\n",
        "\n",
        "Logistic regression, like other machine learning models, can overfit the training data, meaning it learns the training examples too well, including the noise and outliers. This leads to poor performance on new, unseen data.\n",
        "\n",
        "High Dimensionality:\n",
        "\n",
        "When a model has many features (high dimensionality), it's prone to overfitting because it can learn complex relationships that don't generalize well.\n",
        "\n",
        "Simplifying the Model:\n",
        "\n",
        "By penalizing large coefficients, regularization forces the model to rely less on individual features and creates a simpler model that is more likely to generalize well.\n",
        "\n",
        "Improved Generalization:\n",
        "\n",
        "The primary goal of regularization is to improve the model's ability to generalize to unseen data, meaning it makes accurate predictions on new data it hasn't seen during training.\n",
        "\n",
        "Balancing Bias and Variance:\n",
        "\n",
        "Regularization helps find a balance between bias (underfitting) and variance (overfitting) by adding a penalty term that reduces the complexity of the model."
      ],
      "metadata": {
        "id": "nhjgL08edEzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6.Explain the difference between Lasso, Ridge, and Elastic Net regression?\n",
        "\n",
        ".Lasso vs Ridge vs Elastic Net\n",
        "So far, we’ve discussed the basic insights of Lasso, Ridge and Elastic Net. Now, let’s look at a tabular comparison between these three.\n",
        "\n",
        "Features\n",
        "\n",
        "Lasso Regression\n",
        "\n",
        "Ridge Regression\n",
        "\n",
        "Elastic Net Regression\n",
        "\n",
        "Penalty Type\n",
        "\n",
        "L1 Penalty: Lasso uses the absolute values of coefficients.\n",
        "\n",
        "L2 Penalty: Ridge uses the square of the coefficients.\n",
        "\n",
        "L1 + L2 Penalty: Elastic Net uses both absolute and square penalties together.\n",
        "\n",
        "Effect on Coefficients\n",
        "\n",
        "Lasso completely removes unnecessary features by setting their coefficients to zero.\n",
        "\n",
        "Ridge makes all coefficients smaller but doesn’t set them to zero.\n",
        "\n",
        "Elastic Net removes some features and reduces others, balancing both.\n",
        "\n",
        "It is best for\n",
        "\n",
        "It is best when you have many features and want to remove irrelevant ones\n",
        "\n",
        "It is good when all features are useful, but you want to reduce their impact.\n",
        "\n",
        "It is best for when you have many correlated features\n",
        "\n",
        "Hyperparameters involved\n",
        "\n",
        "Alpha: Controls how much regularization is applied. A higher alpha means more shrinkage.\n",
        "\n",
        "Alpha: Similar to Lasso, controls the strength of regularization.\n",
        "\n",
        "Alpha + L1_ratio: Two parameters. Alpha controls regularization strength and L1_ratio adjusts the balance between Lasso and Ridge.\n",
        "\n",
        "Bias and Variance\n",
        "\n",
        "High bias, low variance: Lasso makes the model simpler, leading to higher bias but less overfitting.\n",
        "\n",
        "Low bias, high variance: Ridge keeps all features, leading to less bias but possibly more overfitting.\n",
        "\n",
        "Balance of bias and variance: Elastic Net tries to find the right balance between simplicity and complexity.\n",
        "\n",
        "Strengths\n",
        "\n",
        "Lasso is great for automatically choosing important features.\n",
        "\n",
        "Ridge works well when features are related but shouldn’t be completely removed.\n",
        "\n",
        "Elastic Net combines Lasso’s feature selection and Ridge’s handling of correlations.\n",
        "\n",
        "Weaknesses\n",
        "\n",
        "Lasso can sometimes remove useful features if not tuned properly.\n",
        "\n",
        "Ridge keeps all features, which may not help in high-dimensional data with irrelevant features.\n",
        "\n",
        "Elastic Net is a bit harder to tune due to having two parameters.\n",
        "\n",
        "Example\n",
        "\n",
        "Imagine you have 100 features to predict house prices. Lasso will set the coefficients of irrelevant features (like house color) to zero.\n",
        "\n",
        "If you have 100 features, Ridge will reduce the impact of every feature but won’t completely remove any.\n",
        "\n",
        "If you have features like “size” and “rooms” that are similar, Elastic Net will remove one and shrink the other."
      ],
      "metadata": {
        "id": "14XVLJkQd-vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7.When should we use Elastic Net instead of Lasso or Ridge?\n",
        "\n",
        ".Elastic Net is preferred over Lasso or Ridge when you have a dataset with many correlated features and need to balance both feature selection and preventing overfitting."
      ],
      "metadata": {
        "id": "CUW19w6ie3Bc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8.What is the impact of the regularization parameter (λ) in Logistic Regression?\n",
        "\n",
        ".In Logistic Regression, the regularization parameter (λ) controls the strength of the penalty applied to model complexity, balancing between model fit and complexity."
      ],
      "metadata": {
        "id": "v6lFveylfJ6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What are the key assumptions of Logistic Regression?\n",
        "\n",
        ".The key assumptions of Logistic Regression include a linear relationship between the independent variables and the log-odds of the dependent variable, independent observations, no multicollinearity among independent variables, a large enough sample size, and the absence of outliers.\n"
      ],
      "metadata": {
        "id": "Jc7O9-lcfgEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. What are some alternatives to Logistic Regression for classification tasks?\n",
        "\n",
        ".Several algorithms can be used as alternatives to Logistic Regression for classification tasks, including Support Vector Machines (SVMs), Decision Trees, Random Forests, Neural Networks, and Bayesian methods. Each offers different strengths and weaknesses, making the best choice depend on the specific problem and data."
      ],
      "metadata": {
        "id": "JbPt4dGkf1j8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11.What are Classification Evaluation Metrics?\n",
        "\n",
        ".In classification, evaluation metrics quantify the performance of a model by measuring its ability to correctly predict class labels. Key metrics include accuracy, precision, recall, F1-score, and AUC-ROC, each providing different insights into the model's strengths and weaknesses."
      ],
      "metadata": {
        "id": "QD-K4ToKgH08"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. How does class imbalance affect Logistic Regression.\n",
        "\n",
        ".Class imbalance in logistic regression can lead to a model that is biased towards the majority class, resulting in poor performance on the minority class. This bias arises because the model is trained to minimize the overall error, which can be achieved by predominantly classifying instances of the majority class correctly, even if it misclassifies instances of the minority class."
      ],
      "metadata": {
        "id": "yzheF9ZpgfI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13.What is Hyperparameter Tuning in Logistic Regression?\n",
        "\n",
        ".Hyperparameter tuning in Logistic Regression involves finding the optimal values for parameters that control the learning process, such as the learning rate, regularization strength, and batch size, to improve model performance. These values are set before training begins, and they affect how the model learns from the data."
      ],
      "metadata": {
        "id": "d_CD6k0lguNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. What are different solvers in Logistic Regression? Which one should be used?\n",
        "\n",
        ".In Logistic Regression, different solvers are essentially optimization algorithms used to find the best model parameters (coefficients) given your data. The choice of solver depends on the size and characteristics of your dataset, as well as the type of regularization you want to use."
      ],
      "metadata": {
        "id": "9o9x9V6Dg8sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. How is Logistic Regression extended for multiclass classification?\n",
        "\n",
        ".Logistic Regression can be extended for multiclass classification using two primary methods: One-vs-Rest (OvR) or One-vs-All, and Multinomial Logistic Regression (Softmax Regression). OvR involves training a separate binary classifier for each class, treating it against all others. Multinomial Logistic Regression directly extends the binary logistic regression by using the softmax activation function to predict probabilities for each class."
      ],
      "metadata": {
        "id": "2EvABFzChVwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16.What are the advantages and disadvantages of Logistic Regression?\n",
        "\n",
        ".Advantages and Disadvantages of Logistic Regression.\n",
        "\n",
        "Regression analysis offers several advantages, including its ease of implementation and interpretation, ability to quantify relationships between variables, and versatility in handling various data types. However, it also has disadvantages like its sensitivity to outliers, assumption of linearity, and potential for multicollinearity, which can affect the accuracy and reliability of the model.\n"
      ],
      "metadata": {
        "id": "WudrvJVrhlt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17.What are some use cases of Logistic Regression?\n",
        "\n",
        ".Logistic regression is primarily used for binary classification, predicting the probability of one of two possible outcomes. It's also valuable for preprocessing data, like sorting bank transactions into a smaller range. Its applications span diverse fields like finance, healthcare, and marketing."
      ],
      "metadata": {
        "id": "QnNgppcwiezs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18. What is the difference between Softmax Regression and Logistic Regression?\n",
        "\n",
        ".Softmax Regression is a generalization of Logistic Regression, designed for multi-class classification, while Logistic Regression is primarily used for binary classification. Softmax Regression uses the Softmax function to output a probability distribution over all possible classes, ensuring that these probabilities sum to one. Logistic Regression, on the other hand, uses the Sigmoid function to predict the probability of belonging to one of the two classes."
      ],
      "metadata": {
        "id": "KYmK1qNsitM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. How do we interpret coefficients in Logistic Regression?\n",
        "\n",
        ".In logistic regression, coefficients represent the change in the log-odds of the outcome for a one-unit change in the predictor variable, holding all other variables constant. The exponentiated coefficient (odds ratio) then represents the multiplicative effect on the odds of the event occurring."
      ],
      "metadata": {
        "id": "LqB731YxjGEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PRACTICAL QUESTIONS:"
      ],
      "metadata": {
        "id": "WyaOlbYije_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1.Write a Python program that loads a dataset, splits it into training and testing sets, applies Logistic\n",
        "Regression, and prints the model accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "TE9jGOcTjxuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "lit into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FyuRVURkAWs",
        "outputId": "3f62923a-40e4-4fd5-9c15-f72b45ad1366"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.Write a Python program to apply L1 regularization (Lasso) on a dataset using LogisticRegression(penalty='l1')\n",
        "and print the model accuracy.\n"
      ],
      "metadata": {
        "id": "0JZHTxJ2kcBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with L1 Regularization: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoIFNOFxkkrU",
        "outputId": "b80fbbff-c1a8-4293-9ec3-e088702f22b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with L1 Regularization: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Write a Python program to train Logistic Regression with L2 regularization (Ridge) using\n",
        "LogisticRegression(penalty='l2'). Print model accuracy and coefficients."
      ],
      "metadata": {
        "id": "cy7E-crYk5Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', multi_class='auto', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Model Accuracy with L2 Regularization: {accuracy:.2f}\")\n",
        "print(\"Model Coefficients (one row per class):\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "id": "n2YXybcclDrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Write a Python program to train Logistic Regression with Elastic Net Regularization (penalty='elasticnet')"
      ],
      "metadata": {
        "id": "qUNoGajWlaNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(\n",
        "    penalty='elasticnet',\n",
        "    solver='saga',\n",
        "    l1_ratio=0.5,\n",
        "    max_iter=500\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output results\n",
        "print(f\"Model Accuracy with Elastic Net Regularization: {accuracy:.2f}\")\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_kuKUTdlnEi",
        "outputId": "2fe8964f-d0d5-498d-941f-f13b3ed0a310"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with Elastic Net Regularization: 1.00\n",
            "Model Coefficients:\n",
            "[[ 0.         -1.31684822  2.40411099  0.56660156]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Write a Python program to train a Logistic Regression model for multiclass classification using\n",
        "multi_class='ovr"
      ],
      "metadata": {
        "id": "VwJGfrybl7C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Logistic Regression with One-vs-Rest (OvR) strategy\")\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(\"Model Coefficients (one row per class):\")\n",
        "print(model.coef_)\n"
      ],
      "metadata": {
        "id": "XJH9Lz3OmDn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6.Write a Python program to apply GridSearchCV to tune the hyperparameters (C and penalty) of Logistic\n",
        "Regression. Print the best parameters and accuracy\n"
      ],
      "metadata": {
        "id": "xOgkaZVomTAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(max_iter=200, multi_class='ovr'),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Best Parameters from GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"Test Set Accuracy with Best Model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "kqAaVPdqmY3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Write a Python program to evaluate Logistic Regression using Stratified K-Fold Cross-Validation. Print the\n",
        "average accuracy"
      ],
      "metadata": {
        "id": "oZz1jNKJmwYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "accuracies = cross_val_score(model, X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "print(\"Cross-Validation Accuracies:\", accuracies)\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SRZShQJm4tS",
        "outputId": "c62680f8-f69f-4555-cf9a-e3decc5a6584"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracies: [1.         0.96666667 0.93333333 1.         0.93333333]\n",
            "Average Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8.Write a Python program to load a dataset from a CSV file, apply Logistic Regression, and evaluate its\n",
        "accuracy."
      ],
      "metadata": {
        "id": "RyymDsOenHw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "X = df.drop('target_column', axis=1)\n",
        "y = df['target_column']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "j1nbgQPZnMyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9.Write a Python program to apply RandomizedSearchCV for tuning hyperparameters (C, penalty, solver) in\n",
        "Logistic Regression. Print the best parameters and accuracy"
      ],
      "metadata": {
        "id": "pMtBUqsDnhyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import loguniform\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'C': loguniform(0.001, 100),\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "model = LogisticRegression(max_iter=500, multi_class='ovr')\n",
        "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy', random_state=42, n_jobs=-1)\n",
        "\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"Best Parameters from RandomizedSearchCV:\")\n",
        "print(random_search.best_params_)\n",
        "print(f\"Test Set Accuracy with Best Model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "7yd-fQcGnpc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10.Write a Python program to implement One-vs-One (OvO) Multiclass Logistic Regression and print accuracy"
      ],
      "metadata": {
        "id": "5PdgcCvwn84E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "base_model = LogisticRegression(max_iter=200)\n",
        "ovo_model = OneVsOneClassifier(base_model)\n",
        "\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ovo_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(\"One-vs-One (OvO) Logistic Regression\")\n",
        "print(f\"Test Set Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3X6eLVMoEOF",
        "outputId": "5028c50d-7cff-4e97-ea43-aa97ff397967"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) Logistic Regression\n",
            "Test Set Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11.Write a Python program to train a Logistic Regression model and visualize the confusion matrix for binary\n",
        "classification"
      ],
      "metadata": {
        "id": "el-tEWnWoUBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Pred: 0', 'Pred: 1'], yticklabels=['True: 0', 'True: 1'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "OGEWdAsDoaQO",
        "outputId": "de58e5a5-e1fe-4f33-8f36-a4b1318a74d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. Write a Python program to train a Logistic Regression model and evaluate its performance using Precision,\n",
        "Recall, and F1-Score"
      ],
      "metadata": {
        "id": "H72K4OG_oywe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L94DDBN_pBHV",
        "outputId": "1df6a39b-9d50-4257-b4e7-ad153596b8cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13.Write a Python program to train a Logistic Regression model on imbalanced data and apply class weights to\n",
        "improve model performance."
      ],
      "metadata": {
        "id": "FaA5yhaIpXmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_binary_imbalanced = np.vstack([X_binary[y_binary == 0], X_binary[y_binary == 1][:20]])\n",
        "y_binary_imbalanced = np.concatenate([y_binary[y_binary == 0], y_binary[y_binary == 1][:20]])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary_imbalanced, y_binary_imbalanced, test_size=0.2, random_state=42)\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
        "\n",
        "\n",
        "model = LogisticRegression(max_iter=200, class_weight=class_weight_dict)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaUf8p7Upg4E",
        "outputId": "3d07d843-87f5-46c5-a9c8-17bba592ba20"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1-Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. Write a Python program to train Logistic Regression on the Titanic dataset, handle missing values, and\n",
        "evaluate performance."
      ],
      "metadata": {
        "id": "-U7l5EEEp4kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "numerical_features = ['Age', 'Fare']\n",
        "categorical_features = ['Sex', 'Embarked']\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', SimpleImputer(strategy='median'), numerical_features),\n",
        "        ('cat', Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', LabelEncoder())\n",
        "        ]), categorical_features)\n",
        "    ])\n",
        "\n",
        "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
        "y = df['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "id": "QHS6397jqACE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. Write a Python program to apply feature scaling (Standardization) before training a Logistic Regression\n",
        "model. Evaluate its accuracy and compare results with and without scaling\n"
      ],
      "metadata": {
        "id": "Bj2BTVzhqiGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_with_scaling = model.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "\n",
        "print(f\"Accuracy without Scaling: {accuracy_no_scaling:.2f}\")\n",
        "print(f\"Accuracy with Scaling: {accuracy_with_scaling:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XRngby_qqFM",
        "outputId": "df1fcc9d-c6de-48e0-bcf9-36733e270084"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without Scaling: 1.00\n",
            "Accuracy with Scaling: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17.Write a Python program to train Logistic Regression using a custom learning rate (C=0.5) and evaluate\n",
        "accuracy"
      ],
      "metadata": {
        "id": "sUmQ35OJq-o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(C=0.5, max_iter=200)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Model Accuracy with C=0.5: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amrKeED0rGwa",
        "outputId": "c15148fa-360a-42f5-b794-2118438919c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with C=0.5: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18.Write a Python program to train Logistic Regression and identify important features based on model\n",
        "coefficients."
      ],
      "metadata": {
        "id": "W-vqR-dcrWhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "coefficients = model.coef_.flatten()\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients,\n",
        "    'Absolute Coefficient': np.abs(coefficients)\n",
        "})\n",
        "\n",
        "feature_importance = feature_importance.sort_values(by='Absolute Coefficient', ascending=False)\n",
        "\n",
        "\n",
        "print(\"Feature Importance based on Logistic Regression Coefficients:\")\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdF0pdWGrcGz",
        "outputId": "417ddab3-e575-47c0-8e8b-1d0f9a552a45"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance based on Logistic Regression Coefficients:\n",
            "             Feature  Coefficient  Absolute Coefficient\n",
            "2  petal length (cm)     2.212332              2.212332\n",
            "3   petal width (cm)     0.927443              0.927443\n",
            "1   sepal width (cm)    -0.844458              0.844458\n",
            "0  sepal length (cm)     0.462485              0.462485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19.Write a Python program to train Logistic Regression and evaluate its performance using Cohen’s Kappa\n",
        "Score."
      ],
      "metadata": {
        "id": "-g_F1CxTrwE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Cohen's Kappa Score: {kappa_score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1f5KTNcr1kd",
        "outputId": "3346fcce-c1a9-4460-9993-8be86499a3d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. Write a Python program to train Logistic Regression and visualize the Precision-Recall Curve for binary\n",
        "classificatio:\n"
      ],
      "metadata": {
        "id": "GtiemHF_sGj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='b', label=f'Precision-Recall curve (AUC = {pr_auc:.2f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "GpxJqexBsNod",
        "outputId": "4e310f01-e464-40a9-acfd-a01d75b3486e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21.Write a Python program to train Logistic Regression with different solvers (liblinear, saga, lbfgs) and compare\n",
        "their accuracy"
      ],
      "metadata": {
        "id": "4-wTxxoJshN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "\n",
        "accuracy_dict = {}\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=200)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    accuracy_dict[solver] = accuracy\n",
        "\n",
        "for solver, accuracy in accuracy_dict.items():\n",
        "    print(f\"Accuracy with solver '{solver}': {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGyW_oI4soqu",
        "outputId": "8259b1c9-b30c-4116-9cfd-af498c4ce535"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with solver 'liblinear': 1.00\n",
            "Accuracy with solver 'saga': 1.00\n",
            "Accuracy with solver 'lbfgs': 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23.Write a Python program to train Logistic Regression on both raw and standardized data. Compare their\n",
        "accuracy to see the impact of feature scaling."
      ],
      "metadata": {
        "id": "LaQ8E7_Ws9Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_raw = model.predict(X_test)\n",
        "accuracy_raw = accuracy_score(y_test, y_pred_raw)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "print(f\"Accuracy with raw data: {accuracy_raw:.2f}\")\n",
        "print(f\"Accuracy with standardized data: {accuracy_scaled:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avoQzEvOtEc1",
        "outputId": "bb3086a7-0dd3-4b19-90fd-bda92d5d5e79"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with raw data: 1.00\n",
            "Accuracy with standardized data: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24.Write a Python program to train Logistic Regression and find the optimal C (regularization strength) using\n",
        "cross-validation."
      ],
      "metadata": {
        "id": "dLHTd2mCtYXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "param_grid = {'C': np.logspace(-4, 4, 20)}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_C = grid_search.best_params_['C']\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "model = LogisticRegression(C=best_C, max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Optimal C: {best_C}\")\n",
        "print(f\"Best cross-validation accuracy: {best_score:.2f}\")\n",
        "print(f\"Test set accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Woc_cGnBtexT",
        "outputId": "ccc7d429-0333-470f-c40e-bf853501e5b4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal C: 0.004832930238571752\n",
            "Best cross-validation accuracy: 1.00\n",
            "Test set accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25. Write a Python program to train Logistic Regression, save the trained model using joblib, and load it again to\n",
        "make predictions."
      ],
      "metadata": {
        "id": "shF0PasZt9rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "binary_filter = y != 2\n",
        "X_binary = X[binary_filter]\n",
        "y_binary = y[binary_filter]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "joblib.dump(model, 'logistic_regression_model.pkl')\n",
        "\n",
        "loaded_model = joblib.load('logistic_regression_model.pkl')\n",
        "\n",
        "y_pred = loaded_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"Accuracy of the loaded model: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGEfg_youEMe",
        "outputId": "07a1e24e-a2d0-4ff5-e67f-99e81ff0ca40"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the loaded model: 1.00\n"
          ]
        }
      ]
    }
  ]
}